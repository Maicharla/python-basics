{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"notebook\")\n",
    "#sns.set_context(\"poster\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn import preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Basic Regression Algorithms</h1>\n",
    "\n",
    "Here we review seven of the most well-known regression algorithms. \n",
    "\n",
    "Four variations of linear regression:\n",
    "\n",
    "<ul>\n",
    "    <li>Logistic Regression.</li>\n",
    "    <li>Ridge Linear Regression.</li>\n",
    "    <li>Lasso Linear Regression.</li>\n",
    "    <li>Elastic Net Regression.</li>\n",
    "</ul>\n",
    "and three non-linear that we already know as classification algorithms:\n",
    "<ul>\n",
    "    <li>k-nn - k-Nearest Neighbors.</li>\n",
    "    <li>CART - Classification and Regression Trees.</li>\n",
    "    <li>SVM - Support Vector Machines.</li>\n",
    "</ul>\n",
    "\n",
    "Again we will compare the result and plot it, trying to address the question of which algorithm works better with this dataset. \n",
    "\n",
    "For the dataset, we will use a well-known one that we previously used: the Boston Housing Price with a 10-fold cross-validation. Obviously in this case the objective is to approximate the pricing. \n",
    "\n",
    "As a metric we will use the mean squarred error. Please note that scikit-learn follows a convention that imposes all metrics to be sorted in ascending order, therefore the larger is always better. In order to follow this convention, mean squarred error is expressed with a negative sign, so larger is better (in this case 0). \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"boston.jpg\">\n",
    "<img src=\"Boston-Dataset-char.png\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD  TAX  PTRATIO  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671    2  242     17.8   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622    3  222     18.7   \n",
       "\n",
       "        B  LSTAT  MEDV  \n",
       "0  396.90   4.98  24.0  \n",
       "1  396.90   9.14  21.6  \n",
       "2  392.83   4.03  34.7  \n",
       "3  394.63   2.94  33.4  \n",
       "4  396.90    NaN  36.2  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[  0.006,  18.   ,   2.31 , ...,  15.3  , 396.9  ,   4.98 ],\n",
       "       [  0.027,   0.   ,   7.07 , ...,  17.8  , 396.9  ,   9.14 ],\n",
       "       [  0.027,   0.   ,   7.07 , ...,  17.8  , 392.83 ,   4.03 ],\n",
       "       ...,\n",
       "       [  0.061,   0.   ,  11.93 , ...,  21.   , 396.9  ,   5.64 ],\n",
       "       [  0.11 ,   0.   ,  11.93 , ...,  21.   , 393.45 ,   6.48 ],\n",
       "       [  0.047,   0.   ,  11.93 , ...,  21.   , 396.9  ,   7.88 ]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0     1     2    3      4      5     6       7    8      9    10  \\\n",
       "0  0.00632  18.0  2.31  0.0  0.538  6.575  65.2  4.0900  1.0  296.0  15.3   \n",
       "1  0.02731   0.0  7.07  0.0  0.469  6.421  78.9  4.9671  2.0  242.0  17.8   \n",
       "2  0.02729   0.0  7.07  0.0  0.469  7.185  61.1  4.9671  2.0  242.0  17.8   \n",
       "3  0.03237   0.0  2.18  0.0  0.458  6.998  45.8  6.0622  3.0  222.0  18.7   \n",
       "4  0.06905   0.0  2.18  0.0  0.458  7.147  54.2  6.0622  3.0  222.0  18.7   \n",
       "\n",
       "       11    12  \n",
       "0  396.90  4.98  \n",
       "1  396.90  9.14  \n",
       "2  392.83  4.03  \n",
       "3  394.63  2.94  \n",
       "4  396.90  0.00  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Boston dataset and separate input and output components \n",
    "\n",
    "from numpy import set_printoptions\n",
    "set_printoptions(precision=3)\n",
    "\n",
    "filename=\"HousingData.csv\"\n",
    "b_housing=pd.read_csv(filename)\n",
    "b_housing.head()\n",
    "\n",
    "b_housing.fillna(0,inplace=True) # we have NaN\n",
    "\n",
    "# First we separate into input and output components\n",
    "array=b_housing.values\n",
    "X=array[:,0:13]\n",
    "y=array[:,13]\n",
    "np.set_printoptions(suppress=True)\n",
    "X\n",
    "pd.DataFrame(X).head()\n",
    "\n",
    "# Create the DataFrames for plotting\n",
    "resall=pd.DataFrame()\n",
    "res_w1=pd.DataFrame()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "\n",
    "You all are probably familiar with linear regression! \n",
    "\n",
    "Just a small reminder, it assumes a Gaussian distribution and that all variables are relevant. It also assumes that variables are not highly correlated (a problem called collinearity).\n",
    "\n",
    "We will discuss both the statistical approach to Linear Regression and the Machine Learning approach. You will see that in the statistical approach we seek to fit a model to an existing set of data with the objective to find the components that explain this fit. In contrast, in machine learning we aim to build a model that is able to work well and predict with unknown sets of data. \n",
    "\n",
    "We will use the <b>LinearRegression</b> class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:2495: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>MEDV</td>       <th>  R-squared:         </th> <td>   0.727</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.720</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   100.7</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 12 Nov 2019</td> <th>  Prob (F-statistic):</th> <td>2.06e-129</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>01:37:01</td>     <th>  Log-Likelihood:    </th> <td> -1511.9</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   506</td>      <th>  AIC:               </th> <td>   3052.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   492</td>      <th>  BIC:               </th> <td>   3111.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    13</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "     <td></td>        <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>   <td>   33.2336</td> <td>    5.204</td> <td>    6.387</td> <td> 0.000</td> <td>   23.009</td> <td>   43.458</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CRIM</th>    <td>   -0.1162</td> <td>    0.033</td> <td>   -3.547</td> <td> 0.000</td> <td>   -0.181</td> <td>   -0.052</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ZN</th>      <td>    0.0429</td> <td>    0.014</td> <td>    3.136</td> <td> 0.002</td> <td>    0.016</td> <td>    0.070</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>INDUS</th>   <td>   -0.0315</td> <td>    0.052</td> <td>   -0.601</td> <td> 0.548</td> <td>   -0.134</td> <td>    0.071</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CHAS</th>    <td>    3.1311</td> <td>    0.892</td> <td>    3.510</td> <td> 0.000</td> <td>    1.378</td> <td>    4.884</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NOX</th>     <td>  -17.3454</td> <td>    3.727</td> <td>   -4.654</td> <td> 0.000</td> <td>  -24.669</td> <td>  -10.022</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RM</th>      <td>    4.3036</td> <td>    0.412</td> <td>   10.458</td> <td> 0.000</td> <td>    3.495</td> <td>    5.112</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AGE</th>     <td>   -0.0151</td> <td>    0.010</td> <td>   -1.494</td> <td> 0.136</td> <td>   -0.035</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>DIS</th>     <td>   -1.4844</td> <td>    0.196</td> <td>   -7.592</td> <td> 0.000</td> <td>   -1.868</td> <td>   -1.100</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RAD</th>     <td>    0.2685</td> <td>    0.067</td> <td>    3.998</td> <td> 0.000</td> <td>    0.137</td> <td>    0.400</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TAX</th>     <td>   -0.0109</td> <td>    0.004</td> <td>   -2.874</td> <td> 0.004</td> <td>   -0.018</td> <td>   -0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PTRATIO</th> <td>   -0.9815</td> <td>    0.134</td> <td>   -7.348</td> <td> 0.000</td> <td>   -1.244</td> <td>   -0.719</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>B</th>       <td>    0.0094</td> <td>    0.003</td> <td>    3.373</td> <td> 0.001</td> <td>    0.004</td> <td>    0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>LSTAT</th>   <td>   -0.3918</td> <td>    0.044</td> <td>   -8.817</td> <td> 0.000</td> <td>   -0.479</td> <td>   -0.304</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>188.045</td> <th>  Durbin-Watson:     </th> <td>   1.032</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>1006.627</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.541</td>  <th>  Prob(JB):          </th> <td>2.59e-219</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 9.184</td>  <th>  Cond. No.          </th> <td>1.49e+04</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.49e+04. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                   MEDV   R-squared:                       0.727\n",
       "Model:                            OLS   Adj. R-squared:                  0.720\n",
       "Method:                 Least Squares   F-statistic:                     100.7\n",
       "Date:                Tue, 12 Nov 2019   Prob (F-statistic):          2.06e-129\n",
       "Time:                        01:37:01   Log-Likelihood:                -1511.9\n",
       "No. Observations:                 506   AIC:                             3052.\n",
       "Df Residuals:                     492   BIC:                             3111.\n",
       "Df Model:                          13                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         33.2336      5.204      6.387      0.000      23.009      43.458\n",
       "CRIM          -0.1162      0.033     -3.547      0.000      -0.181      -0.052\n",
       "ZN             0.0429      0.014      3.136      0.002       0.016       0.070\n",
       "INDUS         -0.0315      0.052     -0.601      0.548      -0.134       0.071\n",
       "CHAS           3.1311      0.892      3.510      0.000       1.378       4.884\n",
       "NOX          -17.3454      3.727     -4.654      0.000     -24.669     -10.022\n",
       "RM             4.3036      0.412     10.458      0.000       3.495       5.112\n",
       "AGE           -0.0151      0.010     -1.494      0.136      -0.035       0.005\n",
       "DIS           -1.4844      0.196     -7.592      0.000      -1.868      -1.100\n",
       "RAD            0.2685      0.067      3.998      0.000       0.137       0.400\n",
       "TAX           -0.0109      0.004     -2.874      0.004      -0.018      -0.003\n",
       "PTRATIO       -0.9815      0.134     -7.348      0.000      -1.244      -0.719\n",
       "B              0.0094      0.003      3.373      0.001       0.004       0.015\n",
       "LSTAT         -0.3918      0.044     -8.817      0.000      -0.479      -0.304\n",
       "==============================================================================\n",
       "Omnibus:                      188.045   Durbin-Watson:                   1.032\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1006.627\n",
       "Skew:                           1.541   Prob(JB):                    2.59e-219\n",
       "Kurtosis:                       9.184   Cond. No.                     1.49e+04\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.49e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Linear Regression as used in statistics and social science\n",
    "#  we use statsmodel\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "X_pd=b_housing.copy()\n",
    "X_pd=X_pd.drop([\"MEDV\"],axis=1)\n",
    "y_pd=b_housing[\"MEDV\"]\n",
    "\n",
    "X_pd=sm.add_constant(X_pd)\n",
    "model = sm.OLS(y_pd,X_pd).fit()\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression - MSE -34.090 std 44.046\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept 33.2336\n",
      "Coefficients  [ -0.116   0.043  -0.032   3.131 -17.345   4.304  -0.015  -1.484   0.269\n",
      "  -0.011  -0.981   0.009  -0.392]\n",
      "MAE - Mean Absolute Error 3.308\n",
      "MSE - Mean Square Error  23.058\n",
      "R2    0.727\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression with scikit-learn\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "kfold=KFold(n_splits=10, random_state=7)\n",
    "\n",
    "model=LinearRegression()\n",
    "scoring = \"neg_mean_squared_error\"\n",
    "\n",
    "results=cross_val_score(model, X, y, cv=kfold, scoring=scoring)\n",
    "\n",
    "print(f'Linear Regression - MSE {results.mean():.3f} std {results.std():.3f}')\n",
    "\n",
    "res_w1[\"Res\"]=results\n",
    "res_w1[\"Type\"]=\"Lin\"\n",
    "\n",
    "resall=pd.concat([resall,res_w1], ignore_index=True)\n",
    "\n",
    "# Now lets use it in the same way than the statsmodel\n",
    "\n",
    "model_x=LinearRegression()\n",
    "model_x.fit(X,y)\n",
    "print(f'Intercept {model_x.intercept_:.4f}')\n",
    "print(\"Coefficients \",model_x.coef_)\n",
    "\n",
    "y_pred_x=model_x.predict(X)\n",
    "\n",
    "print(f'MAE - Mean Absolute Error {metrics.mean_absolute_error(y, y_pred_x):.3f}')\n",
    "print(f'MSE - Mean Square Error  {metrics.mean_squared_error(y, y_pred_x):.3f}')\n",
    "print(f'R2    {metrics.r2_score(y, y_pred_x):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Regression\n",
    "\n",
    "The Ridge regession corresponds to modern linear regression algorithms that aim to be more robust to outliers. \n",
    "\n",
    "In this case the loss function is modified to minimize the complexity of the model measured as the sum squared value of the coefficietn values (also called the L2-norm). \n",
    "\n",
    "We will use the <b>Ridge</b> class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression - MSE -33.384 std 44.258\n"
     ]
    }
   ],
   "source": [
    "# Ridge Regression \n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "kfold=KFold(n_splits=10, random_state=7)\n",
    "\n",
    "model=Ridge()\n",
    "scoring = \"neg_mean_squared_error\"\n",
    "\n",
    "results=cross_val_score(model, X, y, cv=kfold, scoring=scoring)\n",
    "\n",
    "print(f'Ridge Regression - MSE {results.mean():.3f} std {results.std():.3f}')\n",
    "\n",
    "res_w1[\"Res\"]=results\n",
    "res_w1[\"Type\"]=\"Ridge\"\n",
    "\n",
    "resall=pd.concat([resall,res_w1], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso Regression\n",
    "\n",
    "Again is a modern regression algorithm that aims a reducing the weight of outliers. \n",
    "\n",
    "In this case the loss function is modified measuring the complexity of the model as the sum absolute value of the coefficients values (also called the L1-norm).\n",
    "\n",
    "You can construct a Lasso model using the <b>Lasso</b> class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Regression - MSE -35.161 std 32.383\n"
     ]
    }
   ],
   "source": [
    "# Lasso Regression \n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "kfold=KFold(n_splits=10, random_state=7)\n",
    "\n",
    "model=Lasso()\n",
    "scoring = \"neg_mean_squared_error\"\n",
    "\n",
    "results=cross_val_score(model, X, y, cv=kfold, scoring=scoring)\n",
    "\n",
    "print(f'Lasso Regression - MSE {results.mean():.3f} std {results.std():.3f}')\n",
    "\n",
    "res_w1[\"Res\"]=results\n",
    "res_w1[\"Type\"]=\"Lasso\"\n",
    "\n",
    "resall=pd.concat([resall,res_w1], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ElasticNet Regression\n",
    "\n",
    "The ElasticNet Regression combines both the Ridge and the Lasso. \n",
    "\n",
    "It penalizes the model using both the L1-norm and the L2-norm. \n",
    "\n",
    "You can construct an ElasticNet model using the <b>ElasticNet</b> class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElasticNet Regression - MSE -33.109 std 26.963\n"
     ]
    }
   ],
   "source": [
    "# ElasticNet Regression \n",
    "\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "kfold=KFold(n_splits=10, random_state=7)\n",
    "\n",
    "model=ElasticNet()\n",
    "scoring = \"neg_mean_squared_error\"\n",
    "\n",
    "results=cross_val_score(model, X, y, cv=kfold, scoring=scoring)\n",
    "\n",
    "print(f'ElasticNet Regression - MSE {results.mean():.3f} std {results.std():.3f}')\n",
    "\n",
    "res_w1[\"Res\"]=results\n",
    "res_w1[\"Type\"]=\"ElasticNet\"\n",
    "\n",
    "resall=pd.concat([resall,res_w1], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-nn k-Nearest Neighbors\n",
    "\n",
    "k-Nearerst Neighbors is a non-linear machine learning algorithm that uses distance metrics to find the most similar k-elements, taking the mean or median outcome of the neighbors as the prediction.\n",
    "\n",
    "One interesting advantage of this algorithm is that we can choose a different metric for calculating the distance. The default metric is Minkowski, equivalent to euclidean (with p=2). It can be easily transformed to Mnahattan distance with p=1. \n",
    "\n",
    "For constructing a knn model for regression you must use the <b>KNeighorsRegressor</b> class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Regression - MSE -97.175 std 50.572\n"
     ]
    }
   ],
   "source": [
    "# KNN Regression \n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "kfold=KFold(n_splits=10, random_state=7)\n",
    "\n",
    "model=KNeighborsRegressor()\n",
    "scoring = \"neg_mean_squared_error\"\n",
    "\n",
    "results=cross_val_score(model, X, y, cv=kfold, scoring=scoring)\n",
    "\n",
    "print(f'KNN Regression - MSE {results.mean():.3f} std {results.std():.3f}')\n",
    "\n",
    "res_w1[\"Res\"]=results\n",
    "res_w1[\"Type\"]=\"KNN\"\n",
    "\n",
    "resall=pd.concat([resall,res_w1], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CART - Classification and Regression Trees\n",
    "\n",
    "Cart builds a binary tree from the data where the splits are chosen greedly evaluating all the attributes in order to minimize a cost function. The default cost metric for regression decision trees is the mean squared error, specified in the criterion parameter.\n",
    "\n",
    "For CART we will use the <b>DecisionTreeRegressor</b> class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Trees Regression - MSE -38.452 std 30.760\n"
     ]
    }
   ],
   "source": [
    "# Decision Trees Regression\n",
    "\n",
    "# Please observe that in this case repeating the algorithm gives different results\n",
    "# scaling doesn't matter in this case - you get different results but inside the range \n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "kfold=KFold(n_splits=10, random_state=7)\n",
    "\n",
    "model=DecisionTreeRegressor()\n",
    "scoring = \"neg_mean_squared_error\"\n",
    "\n",
    "results=cross_val_score(model, X, y, cv=kfold, scoring=scoring)\n",
    "\n",
    "print(f'Decision Trees Regression - MSE {results.mean():.3f} std {results.std():.3f}')\n",
    "\n",
    "res_w1[\"Res\"]=results\n",
    "res_w1[\"Type\"]=\"Trees\"\n",
    "\n",
    "resall=pd.concat([resall,res_w1], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines\n",
    "\n",
    "Support vector machines seeks a line that separates best two classes. The data instances that are closest to this line are, better separating the classes, are called support vectors. \n",
    "\n",
    "Support Vector Machines have the advantage that you can change the kernel function to use. Radial basis function is used by default, a pretty powerful one. \n",
    "\n",
    "You can construct a SVM model for regression with the <b>SVR</b> class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Regression - MSE -91.129 std 71.147\n"
     ]
    }
   ],
   "source": [
    "# SVM - Support Vector Machines\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "kfold=KFold(n_splits=10, random_state=7)\n",
    "\n",
    "model=SVR(gamma=\"auto\")\n",
    "\n",
    "scoring = \"neg_mean_squared_error\"\n",
    "\n",
    "results=cross_val_score(model, X, y, cv=kfold, scoring=scoring)\n",
    "\n",
    "print(f'SVM Regression - MSE {results.mean():.3f} std {results.std():.3f}')\n",
    "\n",
    "res_w1[\"Res\"]=results\n",
    "res_w1[\"Type\"]=\"SVM\"\n",
    "\n",
    "resall=pd.concat([resall,res_w1], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x648 with 0 Axes>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f80e8ff59d0>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f80e8ff59d0>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x648 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Now let's compare them all \n",
    "\n",
    "plt.figure(figsize=(15,9))\n",
    "\n",
    "sns.boxplot(data=resall, x=\"Type\", y=\"Res\")\n",
    "\n",
    "sns.swarmplot(data=resall, x=\"Type\", y=\"Res\", color=\"royalblue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font color=\"red\" size=6>Mission 1</font>\n",
    "\n",
    "a) Let's predict movie revenue using the Movie Database in Kaggle https://www.kaggle.com/c/tmdb-box-office-prediction\n",
    "<br><br>\n",
    "</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
